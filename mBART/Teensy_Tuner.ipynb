{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonrafael29/W266_Final_Project/blob/main/mBART/Teensy_Tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWw0zgUEwp44"
      },
      "source": [
        "Mount google drive to use for file saving and loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hM7I-5bQKA3",
        "outputId": "eab1b02e-ebb4-4da3-f826-36ff0e0f0bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files, drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "%cd gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUi43CtxwlfH"
      },
      "source": [
        "Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY1b6VqT_Nhl",
        "outputId": "85238e24-129b-4152-c186-6b0149ea6679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3 MB 32.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 29.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 86.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 77.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 32.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 101.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 93.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 90.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 32.7 MB/s \n",
            "\u001b[?25h  Building wheel for BLEURT (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q\n",
        "!pip install datasets -q\n",
        "!pip install git+https://github.com/google-research/bleurt.git -q\n",
        "\n",
        "# !wget -N https://storage.googleapis.com/bleurt-oss-21/BLEURT-20.zip . -q\n",
        "# !unzip -q -n BLEURT-20.zip\n",
        "\n",
        "#Downloads the 3-layer distilled model, which is much smaller.\n",
        "# !wget https://storage.googleapis.com/bleurt-oss-21/BLEURT-20-D3.zip .\n",
        "# !unzip BLEURT-20-D3.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA5WDXP1wk9R"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUVDyA503mF9"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from bleurt import score\n",
        "from datasets import load_dataset\n",
        "from transformers import MBartForConditionalGeneration, \\\n",
        "    MBart50TokenizerFast, MBartConfig,\\\n",
        "    TrainingArguments, Trainer\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPs4WGuWwtVZ"
      },
      "source": [
        "Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ2p5znb_2Q7",
        "outputId": "f349f918-f169-426c-8eaa-c30e796bf6d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n"
          ]
        }
      ],
      "source": [
        "ORIGINAL_MODEL_CHECKPOINT = 'facebook/mbart-large-50-many-to-many-mmt'\n",
        "MODEL_CHECKPOINT = 'Mbart/Model/Tiny/checkpoint-1000'\n",
        "\n",
        "PAIRS = [\n",
        "    'en-zh',\n",
        "    'zh-en',\n",
        "    'en-es',\n",
        "    'es-zh',\n",
        "    'es-en',\n",
        "    'zh-es',\n",
        "    ]\n",
        "MBART_DATA = {\n",
        "    'en-zh': {\n",
        "        'size': 69020,\n",
        "        'train': 48444,\n",
        "        'val': 10381,\n",
        "        'src': 'en',\n",
        "        'tgt': 'zh',\n",
        "        'src_tkn': 'en_XX',\n",
        "        'tgt_tkn':'zh_CN',\n",
        "        'tkn': 'zh_CN',\n",
        "        'reverse': False,\n",
        "        'train_path':f'Mbart/Data/en-zh-train_pairs.csv',\n",
        "        'val_path':f'Mbart/Data/en-zh-val_pairs.csv',\n",
        "        'test_path':f'Mbart/Data/en-zh-test_pairs.csv',\n",
        "        },\n",
        "    'zh-en': {\n",
        "        'size': 69020,\n",
        "        'train': 48444,\n",
        "        'val': 10381,\n",
        "        'src': 'zh',\n",
        "        'tgt': 'en',\n",
        "        'src_tkn': 'zh_CN',\n",
        "        'tgt_tkn':'en_XX',\n",
        "        'tkn': 'en_XX',\n",
        "        'reverse': True,\n",
        "        'train_path':f'Mbart/Data/en-zh-train_pairs.csv',\n",
        "        'val_path':f'Mbart/Data/en-zh-val_pairs.csv',\n",
        "        'test_path':f'Mbart/Data/en-zh-test_pairs.csv',\n",
        "        },\n",
        "    'en-es': {\n",
        "        'size': 238511,\n",
        "        'train': 167210,\n",
        "        'val': 35831,\n",
        "        'src': 'en',\n",
        "        'tgt': 'es',\n",
        "        'src_tkn': 'en_XX',\n",
        "        'tgt_tkn':'es_XX',\n",
        "        'tkn': 'es_XX',\n",
        "        'reverse': False,\n",
        "        'train_path':f'Mbart/Data/en-es-train_pairs.csv',\n",
        "        'val_path':f'Mbart/Data/en-es-val_pairs.csv',\n",
        "        'test_path':f'Mbart/Data/en-es-test_pairs.csv',\n",
        "        },\n",
        "    'es-zh': {\n",
        "        'size': 65408,\n",
        "        'train': 45796,\n",
        "        'val': 9814,\n",
        "        'src': 'es',\n",
        "        'tgt': 'zh',\n",
        "        'src_tkn': 'es_XX',\n",
        "        'tgt_tkn':'zh_CN',\n",
        "        'tkn': 'zh_CN',\n",
        "        'reverse': False,\n",
        "        'train_path':f'Mbart/Data/es-zh-train_pairs.csv',\n",
        "        'val_path':f'Mbart/Data/es-zh-val_pairs.csv',\n",
        "        'test_path':f'Mbart/Data/es-zh-test_pairs.csv',\n",
        "        },\n",
        "    'es-en': {\n",
        "        'size': 238511,\n",
        "        'train': 167210,\n",
        "        'val': 35831,\n",
        "        'src': 'es',\n",
        "        'tgt': 'en',\n",
        "        'src_tkn': 'es_XX',\n",
        "        'tgt_tkn':'en_XX',\n",
        "        'tkn': 'en_XX',\n",
        "        'reverse': True,\n",
        "        'train_path':f'Mbart/Data/en-es-train_pairs.csv',\n",
        "        'val_path':f'Mbart/Data/en-es-val_pairs.csv',\n",
        "        'test_path':f'Mbart/Data/en-es-test_pairs.csv',\n",
        "        },\n",
        "    'zh-es': {\n",
        "        'size': 65408,\n",
        "        'train': 45796,\n",
        "        'val': 9814,\n",
        "        'src': 'zh',\n",
        "        'tgt': 'es',\n",
        "        'src_tkn': 'zh_CN',\n",
        "        'tgt_tkn':'es_XX',\n",
        "        'tkn': 'es_XX',\n",
        "        'reverse': True,\n",
        "        'train_path':f'Mbart/Data/es-zh-train_pairs.csv',\n",
        "        'val_path':f'Mbart/Data/es-zh-val_pairs.csv',\n",
        "        'test_path':f'Mbart/Data/es-zh-test_pairs.csv',\n",
        "        },\n",
        "    }\n",
        "\n",
        "DATASET = 'news_commentary'\n",
        "MAX_LENGTH = 50\n",
        "MAX_NEW_TOKENS = 50\n",
        "TRUNCATION = True\n",
        "PADDING = True\n",
        "RETURN_TENSORS = 'pt'\n",
        "BLEURT_CHECKPOINT = './BLEURT-20-D3'\n",
        "N_EXAMPLES = 100\n",
        "\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz9rEqwfw4wj"
      },
      "source": [
        "Load Model, Metrics and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S6dr3hzsErS",
        "outputId": "a8f6a0bc-f9f7-451d-a199-8cc1cd987c3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MBartConfig {\n",
              "  \"_name_or_path\": \"/home/suraj/projects/mbart-50/hf_models/mbart-50-large-many-to-many/\",\n",
              "  \"_num_labels\": 3,\n",
              "  \"activation_dropout\": 0.0,\n",
              "  \"activation_function\": \"relu\",\n",
              "  \"add_bias_logits\": false,\n",
              "  \"add_final_layer_norm\": true,\n",
              "  \"architectures\": [\n",
              "    \"MBartForConditionalGeneration\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classif_dropout\": 0.0,\n",
              "  \"classifier_dropout\": 0.0,\n",
              "  \"d_model\": 1024,\n",
              "  \"decoder_attention_heads\": 8,\n",
              "  \"decoder_ffn_dim\": 2048,\n",
              "  \"decoder_layerdrop\": 0.0,\n",
              "  \"decoder_layers\": 1,\n",
              "  \"decoder_start_token_id\": 2,\n",
              "  \"dropout\": 0.1,\n",
              "  \"early_stopping\": true,\n",
              "  \"encoder_attention_heads\": 8,\n",
              "  \"encoder_ffn_dim\": 2048,\n",
              "  \"encoder_layerdrop\": 0.0,\n",
              "  \"encoder_layers\": 1,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"forced_eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\"\n",
              "  },\n",
              "  \"init_std\": 0.02,\n",
              "  \"is_encoder_decoder\": true,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2\n",
              "  },\n",
              "  \"max_length\": 200,\n",
              "  \"max_position_embeddings\": 1024,\n",
              "  \"model_type\": \"mbart\",\n",
              "  \"normalize_before\": true,\n",
              "  \"normalize_embedding\": true,\n",
              "  \"num_beams\": 5,\n",
              "  \"num_hidden_layers\": 1,\n",
              "  \"output_past\": true,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"scale_embedding\": true,\n",
              "  \"static_position_embeddings\": false,\n",
              "  \"tokenizer_class\": \"MBart50Tokenizer\",\n",
              "  \"transformers_version\": \"4.24.0\",\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 250054\n",
              "}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = MBartConfig.from_pretrained(ORIGINAL_MODEL_CHECKPOINT)\n",
        "\n",
        "config.encoder_layers = 1\n",
        "config.decoder_layers = 1\n",
        "config.num_hidden_layers = 1\n",
        "config.decoder_ffn_dim = 2048\n",
        "config.encoder_ffn_dim = 2048\n",
        "config.encoder_attention_heads = 8\n",
        "config.decoder_attention_heads = 8\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnIWd2aZH8wI",
        "outputId": "5b2209a1-7d2a-48cf-daaa-0f8dd70b97f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/mbart-large-50-many-to-many-mmt were not used when initializing MBartForConditionalGeneration: ['model.encoder.layers.5.fc2.weight', 'model.encoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.encoder.layers.8.fc2.weight', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.7.encoder_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.9.encoder_attn.q_proj.weight', 'model.encoder.layers.11.fc1.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.encoder.layers.10.fc2.bias', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.encoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.10.encoder_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.encoder.layers.10.final_layer_norm.weight', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.10.encoder_attn_layer_norm.bias', 'model.encoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.6.encoder_attn_layer_norm.bias', 'model.encoder.layers.10.fc1.bias', 'model.encoder.layers.6.fc2.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.2.fc1.bias', 'model.encoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.10.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.weight', 'model.encoder.layers.6.final_layer_norm.bias', 'model.encoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.encoder.layers.8.fc2.bias', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.8.encoder_attn.v_proj.weight', 'model.encoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.4.fc1.bias', 'model.encoder.layers.10.fc2.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.q_proj.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.encoder.layers.8.fc1.bias', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.encoder.layers.9.final_layer_norm.weight', 'model.encoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.6.fc1.weight', 'model.encoder.layers.7.self_attn.k_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.weight', 'model.encoder.layers.11.fc2.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.encoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.encoder.layers.2.fc2.bias', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn_layer_norm.weight', 'model.encoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.3.fc2.weight', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.11.encoder_attn.k_proj.bias', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.10.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.encoder.layers.4.fc1.bias', 'model.decoder.layers.8.fc2.weight', 'model.encoder.layers.8.fc1.weight', 'model.encoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn.q_proj.bias', 'model.encoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.3.fc1.weight', 'model.encoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.encoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.encoder.layers.11.fc1.bias', 'model.decoder.layers.6.encoder_attn.out_proj.weight', 'model.encoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.7.fc2.weight', 'model.encoder.layers.8.self_attn_layer_norm.bias', 'model.encoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.encoder.layers.1.fc1.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.encoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.6.encoder_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.k_proj.bias', 'model.decoder.layers.1.fc1.weight', 'model.encoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.10.fc1.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.6.encoder_attn.q_proj.bias', 'model.decoder.layers.8.encoder_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.encoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.q_proj.weight', 'model.encoder.layers.1.self_attn.q_proj.bias', 'model.encoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.8.encoder_attn.out_proj.weight', 'model.decoder.layers.9.encoder_attn.v_proj.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.2.fc2.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.9.fc1.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.v_proj.bias', 'model.encoder.layers.9.fc1.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.encoder.layers.6.fc2.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.encoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.6.final_layer_norm.weight', 'model.encoder.layers.6.self_attn.q_proj.bias', 'model.encoder.layers.4.fc2.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.encoder.layers.7.fc1.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.bias', 'model.encoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.encoder.layers.2.fc1.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.weight', 'model.decoder.layers.8.encoder_attn.v_proj.bias', 'model.encoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.encoder.layers.4.fc1.weight', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.2.fc1.bias', 'model.encoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.encoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.7.encoder_attn.q_proj.bias', 'model.encoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.encoder.layers.7.fc2.weight', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.6.encoder_attn.v_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.9.encoder_attn_layer_norm.bias', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.encoder.layers.7.fc1.weight', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.fc2.bias', 'model.encoder.layers.11.fc2.bias', 'model.decoder.layers.9.encoder_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.encoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.v_proj.weight', 'model.encoder.layers.9.fc2.bias', 'model.encoder.layers.1.fc2.weight', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.11.fc1.weight', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.encoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.layers.11.fc2.bias', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.encoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.encoder.layers.5.fc1.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.11.encoder_attn.v_proj.weight', 'model.encoder.layers.1.fc2.bias', 'model.decoder.layers.10.encoder_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.9.encoder_attn.out_proj.bias', 'model.encoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.6.encoder_attn.v_proj.bias', 'model.encoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.7.encoder_attn.out_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.encoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.11.final_layer_norm.bias', 'model.encoder.layers.9.fc2.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.encoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.encoder_attn.v_proj.weight', 'model.encoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.7.encoder_attn.out_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.bias', 'model.encoder.layers.10.self_attn.k_proj.weight', 'model.encoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.6.encoder_attn.k_proj.bias', 'model.encoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.6.encoder_attn_layer_norm.weight', 'model.decoder.layers.10.encoder_attn.out_proj.bias', 'model.encoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.encoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.6.fc2.weight', 'model.encoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.encoder.layers.6.fc1.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.8.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.encoder.layers.9.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.q_proj.weight', 'model.encoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.11.encoder_attn.out_proj.weight', 'model.decoder.layers.7.encoder_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.k_proj.weight', 'model.encoder.layers.1.fc1.weight', 'model.decoder.layers.8.encoder_attn_layer_norm.bias', 'model.encoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.8.encoder_attn.q_proj.bias', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.3.fc2.weight', 'model.encoder.layers.8.self_attn.v_proj.weight', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.encoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.3.fc1.bias', 'model.encoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.8.encoder_attn.k_proj.weight', 'model.decoder.layers.9.encoder_attn.out_proj.weight', 'model.encoder.layers.8.self_attn.out_proj.weight', 'model.encoder.layers.4.fc2.bias', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.encoder.layers.7.self_attn_layer_norm.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.1.fc2.weight', 'model.encoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.encoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.11.encoder_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.11.encoder_attn.out_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.2.fc1.weight', 'model.encoder.layers.3.fc1.bias', 'model.decoder.layers.6.encoder_attn.out_proj.bias', 'model.decoder.layers.7.encoder_attn.k_proj.weight', 'model.encoder.layers.5.fc2.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.9.encoder_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.10.encoder_attn.v_proj.weight', 'model.decoder.layers.10.encoder_attn.q_proj.weight', 'model.encoder.layers.1.self_attn_layer_norm.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.11.encoder_attn.q_proj.weight', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.encoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.encoder.layers.7.final_layer_norm.bias', 'model.encoder.layers.10.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.6.encoder_attn.k_proj.weight', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.encoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.10.encoder_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.encoder.layers.5.fc1.bias', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.encoder.layers.7.fc2.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.encoder.layers.9.self_attn.out_proj.bias', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.encoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.9.encoder_attn.k_proj.bias', 'model.decoder.layers.11.encoder_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing MBartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MBartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of MBartForConditionalGeneration were not initialized from the model checkpoint at facebook/mbart-large-50-many-to-many-mmt and are newly initialized because the shapes did not match:\n",
            "- model.encoder.layers.0.fc1.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([2048, 1024]) in the model instantiated\n",
            "- model.encoder.layers.0.fc1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([2048]) in the model instantiated\n",
            "- model.encoder.layers.0.fc2.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([1024, 2048]) in the model instantiated\n",
            "- model.decoder.layers.0.fc1.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([2048, 1024]) in the model instantiated\n",
            "- model.decoder.layers.0.fc1.bias: found shape torch.Size([4096]) in the checkpoint and torch.Size([2048]) in the model instantiated\n",
            "- model.decoder.layers.0.fc2.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([1024, 2048]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the metrics model and tokenizer for use in the next cell\n",
        "\n",
        "bleurt_metric = score.LengthBatchingBleurtScorer(BLEURT_CHECKPOINT)\n",
        "model = MBartForConditionalGeneration.from_pretrained(ORIGINAL_MODEL_CHECKPOINT, config=config, ignore_mismatched_sizes=True)\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(ORIGINAL_MODEL_CHECKPOINT)\n",
        "#model = torch.load('Mbart/Model/epoch-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIiEDLXMbSg5"
      },
      "outputs": [],
      "source": [
        "def supervised_preprocessor(src_data, tgt_data, tokenizer, src_tkn, tgt_tkn):\n",
        "  tokenizer.src_lang = src_tkn\n",
        "  tokenizer.tgt_lang = tgt_tkn\n",
        " \n",
        "  inputs = tokenizer(\n",
        "        text=[np.array2string(src_data)],\n",
        "        text_target=[np.array2string(tgt_data)],\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding='max_length',\n",
        "        truncation=TRUNCATION,\n",
        "        return_tensors=RETURN_TENSORS,\n",
        "        )\n",
        "\n",
        "  return {'input_ids':inputs.input_ids[0],\n",
        "           'attention_mask':inputs.attention_mask[0],\n",
        "           'labels':inputs.labels[0],\n",
        "          }\n",
        "\n",
        "def eval_preprocessor(src_data, tgt_data, tokenizer, src_tkn, tgt_tkn):\n",
        "  tokenizer.src_lang = src_tkn\n",
        "  tokenizer.tgt_lang = tgt_tkn\n",
        " \n",
        "  src_tkns = tokenizer(\n",
        "        text=[np.array2string(src_data)],\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding='max_length',\n",
        "        truncation=TRUNCATION,\n",
        "        return_tensors=RETURN_TENSORS,\n",
        "        )\n",
        "  \n",
        "  tgt_tkns = tokenizer(\n",
        "        text_target=[np.array2string(tgt_data)],\n",
        "        max_length=MAX_LENGTH,\n",
        "        padding='max_length',\n",
        "        truncation=TRUNCATION,\n",
        "        return_tensors=RETURN_TENSORS,\n",
        "        return_attention_mask=False,\n",
        "        )\n",
        "\n",
        "  tgt_tkn_id = torch.tensor(tokenizer.lang_code_to_id[tgt_tkn])\n",
        "  return {'inputs' : {'input_ids':src_tkns.input_ids.cuda(),\n",
        "                      'attention_mask':src_tkns.attention_mask.cuda(),\n",
        "                      'decoder_input_ids':tgt_tkn_id},\n",
        "          'labels' : tgt_tkns.input_ids.cuda(),}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIdyJlNfU47I"
      },
      "outputs": [],
      "source": [
        " class TranslationDataIterator:\n",
        "    \n",
        "    def __init__(self,\n",
        "                 tokenizer,\n",
        "                 n_examples,\n",
        "                 max_load_at_once,\n",
        "                 data_filename,\n",
        "                 src,\n",
        "                 tgt,\n",
        "                 src_tkn,\n",
        "                 tgt_tkn,\n",
        "                 max_length=MAX_LENGTH,\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_examples = n_examples\n",
        "        self.max_load_at_once = max_load_at_once\n",
        "        self.data_filename = data_filename\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.src_tkn = src_tkn\n",
        "        self.tgt_tkn = tgt_tkn\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "        self.row_order = np.arange(1, self.n_examples+1)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # Load first chunk of max_load_at_once examples\n",
        "        self.df_curr_loaded = self._load_next_chunk(0)\n",
        "        self.curr_idx_in_load = 0\n",
        "    \n",
        "    def _load_next_chunk(self, idx):\n",
        "        load_start = idx\n",
        "        load_end = idx + self.max_load_at_once\n",
        "\n",
        "        # Indices to skip are the ones in the shuffled row_order before and\n",
        "        # after the chunk we'll use for this chunk\n",
        "        load_idx_skip = self.row_order[:load_start] + self.row_order[load_end:]\n",
        "        self.df_curr_loaded = pd.read_csv(self.data_filename, skiprows=load_idx_skip)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.df_curr_loaded is None or self.curr_idx_in_load >= len(self.df_curr_loaded):\n",
        "            self._load_next_chunk(idx)\n",
        "            self.curr_idx_in_load = 0\n",
        "        \n",
        "        src_data = self.df_curr_loaded[[src]].values.astype(str)[self.curr_idx_in_load]\n",
        "        tgt_data = self.df_curr_loaded[[tgt]].values.astype(str)[self.curr_idx_in_load]\n",
        "        self.curr_idx_in_load += 1\n",
        "\n",
        "        item_data = supervised_preprocessor(\n",
        "            src_data,\n",
        "            tgt_data,\n",
        "            self.tokenizer,\n",
        "            self.src_tkn,\n",
        "            self.tgt_tkn,\n",
        "        )\n",
        "        \n",
        "        return item_data\n",
        "    \n",
        "    def __call__(self):\n",
        "        for i in range(self.__len__()):\n",
        "            yield self.__getitem__(i)\n",
        "            \n",
        "            if i == self.__len__()-1:\n",
        "                self.on_epoch_end()\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.row_order = list(np.random.permutation(self.row_order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wjf976qItFv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeGJIXCzTbHR"
      },
      "outputs": [],
      "source": [
        "# class CustomTrainer(Trainer):\n",
        "#   def compute_loss(self,model,inputs, return_outputs=False):\n",
        "#     labels=inputs.get(\"labels\")\n",
        "#     outputs = model(**inputs, decoder_start_token_id=output_tkn)\n",
        "#     logits = outputs.get(\"logits\")\n",
        "#     loss_fct = nn.CrossEntropyLoss()\n",
        "#     loss = loss_fct(logits.view(-1,self.model.config.vocab_size), labels.view(-1))\n",
        "#     return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def compute_metrics(eval_prediction):\n",
        "  label_ids = eval_prediction.label_ids\n",
        "  generated_ids = eval_prediction.predictions\n",
        "  generated = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "  label = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "  bleurt_score = score(references=label, candidates=generated)\n",
        "\n",
        "  return {\n",
        "      \"bleurt\" : bleurt_score\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DYw922YDZCG"
      },
      "outputs": [],
      "source": [
        " class PredictIterator(TranslationDataIterator):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 tokenizer,\n",
        "                 n_examples,\n",
        "                 max_load_at_once,\n",
        "                 data_filename,\n",
        "                 src,\n",
        "                 tgt,\n",
        "                 src_tkn,\n",
        "                 tgt_tkn,\n",
        "                 max_length=MAX_LENGTH,\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_examples = n_examples\n",
        "        self.max_load_at_once = max_load_at_once\n",
        "        self.data_filename = data_filename\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.src_tkn = src_tkn\n",
        "        self.tgt_tkn = tgt_tkn\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "        self.row_order = np.arange(1, self.n_examples+1)\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        # Load first chunk of max_load_at_once examples\n",
        "        self.df_curr_loaded = self._load_next_chunk(0)\n",
        "        self.curr_idx_in_load = 0\n",
        "    \n",
        "    def _load_next_chunk(self, idx):\n",
        "        load_start = idx\n",
        "        load_end = idx + self.max_load_at_once\n",
        "\n",
        "        # Indices to skip are the ones in the shuffled row_order before and\n",
        "        # after the chunk we'll use for this chunk\n",
        "        load_idx_skip = self.row_order[:load_start] + self.row_order[load_end:]\n",
        "        self.df_curr_loaded = pd.read_csv(self.data_filename, skiprows=load_idx_skip)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_examples    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.df_curr_loaded is None or self.curr_idx_in_load >= len(self.df_curr_loaded):\n",
        "            self._load_next_chunk(idx)\n",
        "            self.curr_idx_in_load = 0\n",
        "        \n",
        "        src_data = self.df_curr_loaded[[src]].values.astype(str)[self.curr_idx_in_load]\n",
        "        tgt_data = self.df_curr_loaded[[tgt]].values.astype(str)[self.curr_idx_in_load]\n",
        "        self.curr_idx_in_load += 1\n",
        "\n",
        "        item_data = eval_preprocessor(\n",
        "            src_data,\n",
        "            tgt_data,\n",
        "            self.tokenizer,\n",
        "            self.src_tkn,\n",
        "            self.tgt_tkn,\n",
        "        )\n",
        "        \n",
        "        return item_data\n",
        "    \n",
        "    def __call__(self):\n",
        "        for i in range(self.__len__()):\n",
        "            yield self.__getitem__(i)\n",
        "            \n",
        "            if i == self.__len__()-1:\n",
        "                self.on_epoch_end()\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.row_order = list(np.random.permutation(self.row_order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ5xzZ41QpOU"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH=f\"Mbart/Model/Teensy\"\n",
        "BATCH_SIZE=32\n",
        "\n",
        "TRAINER_PARAMS = TrainingArguments(\n",
        "    MODEL_PATH,\n",
        "    evaluation_strategy='no',\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=1,\n",
        "    dataloader_drop_last=True,\n",
        "    resume_from_checkpoint=True,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTUONmi9kqvk"
      },
      "outputs": [],
      "source": [
        "torch.save(model,'Mbart/Model/Teensy/base2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "KbwarlBqU-aV",
        "outputId": "e252cc7d-3248-4285-d253-865a9204cbf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training translation en-zh mini model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 48444\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1513\n",
            "  Number of trainable parameters = 279164928\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1015' max='1513' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1015/1513 20:00 < 09:50, 0.84 it/s, Epoch 0.67/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.771400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.526800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to Mbart/Model/Teensy/checkpoint-500\n",
            "Configuration saved in Mbart/Model/Teensy/checkpoint-500/config.json\n",
            "Model weights saved in Mbart/Model/Teensy/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to Mbart/Model/Teensy/checkpoint-1000\n",
            "Configuration saved in Mbart/Model/Teensy/checkpoint-1000/config.json\n",
            "Model weights saved in Mbart/Model/Teensy/checkpoint-1000/pytorch_model.bin\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d553a4358459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m       )\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmbart_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-210a788297aa>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_idx_in_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m        \u001b[0msrc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_curr_loaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_idx_in_load\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m        \u001b[0mtgt_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_curr_loaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_idx_in_load\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_idx_in_load\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "# Create the data generators for train and validation data, tensorflow version\n",
        "\n",
        "max_length = MAX_LENGTH\n",
        "max_load_at_once = 200 \n",
        "\n",
        "# Load individual dataset, score BLEU and BLEURT scores for dataset\n",
        "for p in range(0,len(PAIRS)):\n",
        "    train_len = MBART_DATA[PAIRS[p]][\"train\"]\n",
        "    val_len = MBART_DATA[PAIRS[p]][\"val\"]\n",
        "    src = MBART_DATA[PAIRS[p]][\"src\"]\n",
        "    tgt = MBART_DATA[PAIRS[p]][\"tgt\"]\n",
        "    src_tkn = MBART_DATA[PAIRS[p]][\"src_tkn\"]\n",
        "    tgt_tkn = MBART_DATA[PAIRS[p]][\"tgt_tkn\"]\n",
        "    train_file = MBART_DATA[PAIRS[p]][\"train_path\"]\n",
        "    val_file = MBART_DATA[PAIRS[p]][\"val_path\"]\n",
        "\n",
        "    print(f\"Training translation {PAIRS[p]} mini model\")\n",
        "\n",
        "    train_data_generator = TranslationDataIterator(\n",
        "        tokenizer=tokenizer,\n",
        "        n_examples=train_len,\n",
        "        max_load_at_once=max_load_at_once,\n",
        "        data_filename=train_file,\n",
        "        max_length=max_length,\n",
        "        src=src,\n",
        "        tgt=tgt,\n",
        "        src_tkn=src_tkn,\n",
        "        tgt_tkn=tgt_tkn,\n",
        "    )\n",
        "\n",
        "    valid_data_generator = TranslationDataIterator(\n",
        "        tokenizer=tokenizer,\n",
        "        n_examples=val_len,\n",
        "        max_load_at_once=max_load_at_once,\n",
        "        data_filename=val_file,\n",
        "        max_length=max_length,\n",
        "        src=src,\n",
        "        tgt=tgt,\n",
        "        src_tkn=src_tkn,\n",
        "        tgt_tkn=tgt_tkn,\n",
        "      )\n",
        "    troubleshooting_data_generator = PredictIterator(\n",
        "        tokenizer=tokenizer,\n",
        "        n_examples=val_len,\n",
        "        max_load_at_once=max_load_at_once,\n",
        "        data_filename=val_file,\n",
        "        max_length=max_length,\n",
        "        src=src,\n",
        "        tgt=tgt,\n",
        "        src_tkn=src_tkn,\n",
        "        tgt_tkn=tgt_tkn,\n",
        "      )\n",
        "\n",
        "    mbart_trainer = Trainer(\n",
        "        model=model,\n",
        "        args=TRAINER_PARAMS,\n",
        "        train_dataset=train_data_generator,\n",
        "        eval_dataset=None,\n",
        "        compute_metrics=None,\n",
        "      )\n",
        "    mbart_trainer.train()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ow3GACXTsFXm"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'Mbart/Model/Single/epoch-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lKIgz46sFak"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), 'Mbart/Model/Tiny/epoch-2-state')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kObM0EREC74k",
        "outputId": "3d900b64-1626-47d2-ebcd-d0a456cecdeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "tLV0Q9GrsFe5",
        "outputId": "cd2c0947-8504-4a6d-99f1-f29b8abe1d77"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b8591eb44077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1208\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MBartForConditionalGeneration' object has no attribute 'shape'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgOVEly4sFhx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDV61A09sFkp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m90W8pr-Db_1",
        "outputId": "2ba90c1c-c1af-4061-a1cf-a7c9d8737414"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'inputs': {'input_ids': tensor([[250025,    378,     25,   1189,  37415,   5714,      4,  26871,  55899,\n",
              "            17989,  60353, 226934,    264,  48616, 123843,   1988,     30, 124920,\n",
              "             1535,  37928,    213,   4617,   2920,   3300,  13447,     37,   5250,\n",
              "             2100,    213, 156455,   1420,  12590,  23470,   7447,   1493,  95539,\n",
              "                4,   1288,  27839,   1635,   1288,  48616,   4491,  27043,   5525,\n",
              "            11608,  53989,  32870,  72926,      2]], device='cuda:0'),\n",
              "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "           1, 1]], device='cuda:0'),\n",
              "  'decoder_input_ids': tensor(250005)},\n",
              " 'labels': tensor([[250005,    378,     25,    284,  26897,      8,    576, 110245,      7,\n",
              "               4,    576,  28214,  26850,      7,   6805,   1005, 190037,      7,\n",
              "             121,   1011,    377,  40578,     10,     21,  41767,   3812,      6,\n",
              "            2305,   3296,    113, 104388,      5,   6646,    279,    840,     22,\n",
              "           15127,   8797,    143,   3459,    113,  18316,    279,   4017,  18451,\n",
              "              22,    576,  77142,  55105,      2]], device='cuda:0')}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "troubleshooting_data_generator[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "0AbHzeU_Gco2",
        "outputId": "2c6b5e19-a768-4a61-8dce-ea2e9f8f0aa3"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-51ea1ee089db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtroubleshooting_data_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3438\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3439\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3440\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3441\u001b[0m         )\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
          ]
        }
      ],
      "source": [
        "tokenizer.decode(troubleshooting_data_generator[0]['inputs']['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaBv5yqtiYB7"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(troubleshooting_data_generator[0]['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvc3CLN5lOVz"
      },
      "outputs": [],
      "source": [
        "troubleshooting_data_generator[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9BcqSzvt_L-"
      },
      "outputs": [],
      "source": [
        "original = tokenizer.decode(troubleshooting_data_generator[0]['inputs']['input_ids'][0])\n",
        "original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUqoifAjvUJo"
      },
      "outputs": [],
      "source": [
        "generated_none = model.generate(input_ids=troubleshooting_data_generator[0]['inputs']['input_ids'], max_length=50)\n",
        "generated_none"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PGOGLzIvb-I"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(generated_none[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4mC2yZzrW-X"
      },
      "outputs": [],
      "source": [
        "generated_zh = model.generate(input_ids=troubleshooting_data_generator[0]['inputs']['input_ids'], forced_bos_token_id=tokenizer.lang_code_to_id['zh_CN'], max_length=50)\n",
        "generated_zh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTm6FkR5teMJ"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(generated_zh[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqPzlxfpur6J"
      },
      "outputs": [],
      "source": [
        "generated_es = model.generate(input_ids=troubleshooting_data_generator[0]['inputs']['input_ids'], forced_bos_token_id=tokenizer.lang_code_to_id['es_XX'], max_length=50)\n",
        "generated_es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o165vW0qu8nQ"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(generated_es[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8SLN1AvsZOG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAq8AhX4ihQl"
      },
      "outputs": [],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRnvLPDWGc0t"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9bEWjiXDcFL"
      },
      "outputs": [],
      "source": [
        "src_tkn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oclES5prDbQe"
      },
      "outputs": [],
      "source": [
        "    mbart_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU8dCm9hgINe"
      },
      "outputs": [],
      "source": [
        "print(torch.cuda.memory_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWqjuHDo-wDs"
      },
      "outputs": [],
      "source": [
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXsPYmRc-7Ag"
      },
      "outputs": [],
      "source": [
        "print(torch.cuda.memory_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlgP0KLM-8Ri"
      },
      "outputs": [],
      "source": [
        " torch.cuda.synchronize()\n",
        " torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeUTYvko_iKa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}